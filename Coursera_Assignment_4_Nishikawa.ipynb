{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c2effde",
   "metadata": {},
   "source": [
    "# Assignment 4: Becoming an Independent Data Scientist\n",
    "\n",
    "*Applied Plotting, Charting & Data Representation in Python*\n",
    "\n",
    "Takashi Nishikawa\n",
    "\n",
    "June 4, 2022\n",
    "\n",
    "### Selected region\n",
    "Michigan, United States\n",
    "\n",
    "### Domain category of data\n",
    "Weather phenomena\n",
    "\n",
    "### Research question\n",
    "How has the number of tornados changed over the past several decades in Michigan and how does it compare to those of the other Midwestern states?\n",
    "\n",
    "### Data set\n",
    "Storm Events Database, by the National Centers of Environmental Information (https://www.ncdc.noaa.gov/stormevents/). This database contains data on storms and other significant weather events in the US since 1950, including tornados.\n",
    "\n",
    "### Data collection\n",
    "The names of relevant data files from https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/ were copied and pasted into a text file `file_names.txt`:\n",
    "\n",
    "```\n",
    "StormEvents_details-ftp_v1.0_d1950_c20210803.csv.gz\t2021-08-05 09:53\t10K\t \n",
    "StormEvents_details-ftp_v1.0_d1951_c20210803.csv.gz\t2021-08-05 09:56\t12K\t \n",
    "StormEvents_details-ftp_v1.0_d1952_c20210803.csv.gz\t2021-08-05 09:56\t12K\t \n",
    "StormEvents_details-ftp_v1.0_d1953_c20210803.csv.gz\t2021-08-05 09:56\t21K\t \n",
    "StormEvents_details-ftp_v1.0_d1954_c20210803.csv.gz\t2021-08-05 09:56\t26K\t \n",
    "StormEvents_details-ftp_v1.0_d1955_c20210803.csv.gz\t2021-08-05 09:56\t52K\t \n",
    "StormEvents_details-ftp_v1.0_d1956_c20210803.csv.gz\t2021-08-05 09:56\t62K\t \n",
    "StormEvents_details-ftp_v1.0_d1957_c20210803.csv.gz\t2021-08-05 09:56\t80K\t \n",
    "StormEvents_details-ftp_v1.0_d1958_c20210803.csv.gz\t2021-08-05 09:56\t69K\t \n",
    "StormEvents_details-ftp_v1.0_d1959_c20210803.csv.gz\t2021-08-05 09:56\t66K\t \n",
    "StormEvents_details-ftp_v1.0_d1960_c20210803.csv.gz\t2021-08-05 09:56\t70K\t \n",
    "StormEvents_details-ftp_v1.0_d1961_c20210803.csv.gz\t2021-08-05 09:56\t81K\t \n",
    "StormEvents_details-ftp_v1.0_d1962_c20210803.csv.gz\t2021-08-05 09:56\t83K\t \n",
    "StormEvents_details-ftp_v1.0_d1963_c20210803.csv.gz\t2021-08-05 09:56\t70K\t \n",
    "StormEvents_details-ftp_v1.0_d1964_c20210803.csv.gz\t2021-08-05 09:56\t84K\t \n",
    "StormEvents_details-ftp_v1.0_d1965_c20210803.csv.gz\t2021-08-05 09:56\t102K\t \n",
    "StormEvents_details-ftp_v1.0_d1966_c20210803.csv.gz\t2021-08-05 09:56\t81K\t \n",
    "StormEvents_details-ftp_v1.0_d1967_c20210803.csv.gz\t2021-08-05 09:56\t95K\t \n",
    "StormEvents_details-ftp_v1.0_d1968_c20210803.csv.gz\t2021-08-05 09:56\t112K\t \n",
    "StormEvents_details-ftp_v1.0_d1969_c20210803.csv.gz\t2021-08-05 09:56\t100K\t \n",
    "StormEvents_details-ftp_v1.0_d1970_c20210803.csv.gz\t2021-08-05 09:56\t112K\t \n",
    "StormEvents_details-ftp_v1.0_d1971_c20210803.csv.gz\t2021-08-05 09:56\t123K\t \n",
    "StormEvents_details-ftp_v1.0_d1972_c20220425.csv.gz\t2022-04-25 15:06\t80K\t \n",
    "StormEvents_details-ftp_v1.0_d1973_c20220425.csv.gz\t2022-04-25 15:06\t157K\t \n",
    "StormEvents_details-ftp_v1.0_d1974_c20220425.csv.gz\t2022-04-25 15:06\t183K\t \n",
    "StormEvents_details-ftp_v1.0_d1975_c20220425.csv.gz\t2022-04-25 15:06\t172K\t \n",
    "StormEvents_details-ftp_v1.0_d1976_c20220425.csv.gz\t2022-04-25 15:06\t133K\t \n",
    "StormEvents_details-ftp_v1.0_d1977_c20220425.csv.gz\t2022-04-25 15:06\t137K\t \n",
    "StormEvents_details-ftp_v1.0_d1978_c20220425.csv.gz\t2022-04-25 15:06\t133K\t \n",
    "StormEvents_details-ftp_v1.0_d1979_c20220425.csv.gz\t2022-04-25 15:06\t151K\t \n",
    "StormEvents_details-ftp_v1.0_d1980_c20220425.csv.gz\t2022-04-25 15:06\t211K\t \n",
    "StormEvents_details-ftp_v1.0_d1981_c20220425.csv.gz\t2022-04-25 15:06\t159K\t \n",
    "StormEvents_details-ftp_v1.0_d1982_c20220425.csv.gz\t2022-04-25 15:06\t240K\t \n",
    "StormEvents_details-ftp_v1.0_d1983_c20220425.csv.gz\t2022-04-25 15:06\t270K\t \n",
    "StormEvents_details-ftp_v1.0_d1984_c20220425.csv.gz\t2022-04-25 15:06\t248K\t \n",
    "StormEvents_details-ftp_v1.0_d1985_c20220425.csv.gz\t2022-04-25 15:06\t263K\t \n",
    "StormEvents_details-ftp_v1.0_d1986_c20220425.csv.gz\t2022-04-25 15:06\t291K\t \n",
    "StormEvents_details-ftp_v1.0_d1987_c20220425.csv.gz\t2022-04-25 15:06\t249K\t \n",
    "StormEvents_details-ftp_v1.0_d1988_c20220425.csv.gz\t2022-04-25 15:06\t250K\t \n",
    "StormEvents_details-ftp_v1.0_d1989_c20220425.csv.gz\t2022-04-25 15:06\t348K\t \n",
    "StormEvents_details-ftp_v1.0_d1990_c20220425.csv.gz\t2022-04-25 15:06\t377K\t \n",
    "StormEvents_details-ftp_v1.0_d1991_c20220425.csv.gz\t2022-04-25 15:06\t426K\t \n",
    "StormEvents_details-ftp_v1.0_d1992_c20220425.csv.gz\t2022-04-25 15:06\t468K\t \n",
    "StormEvents_details-ftp_v1.0_d1993_c20220425.csv.gz\t2022-04-25 15:06\t550K\t \n",
    "StormEvents_details-ftp_v1.0_d1994_c20220425.csv.gz\t2022-04-25 15:06\t1.0M\t \n",
    "StormEvents_details-ftp_v1.0_d1995_c20220425.csv.gz\t2022-04-25 15:06\t1.3M\t \n",
    "StormEvents_details-ftp_v1.0_d1996_c20220425.csv.gz\t2022-04-25 15:06\t6.0M\t \n",
    "StormEvents_details-ftp_v1.0_d1997_c20220425.csv.gz\t2022-04-25 15:06\t6.3M\t \n",
    "StormEvents_details-ftp_v1.0_d1998_c20220425.csv.gz\t2022-04-25 15:06\t9.8M\t \n",
    "StormEvents_details-ftp_v1.0_d1999_c20220425.csv.gz\t2022-04-25 15:06\t9.9M\t \n",
    "StormEvents_details-ftp_v1.0_d2000_c20220425.csv.gz\t2022-04-25 15:06\t7.5M\t \n",
    "StormEvents_details-ftp_v1.0_d2001_c20220425.csv.gz\t2022-04-25 15:06\t6.6M\t \n",
    "StormEvents_details-ftp_v1.0_d2002_c20220425.csv.gz\t2022-04-25 15:06\t6.9M\t \n",
    "StormEvents_details-ftp_v1.0_d2003_c20220425.csv.gz\t2022-04-25 15:05\t6.9M\t \n",
    "StormEvents_details-ftp_v1.0_d2004_c20220425.csv.gz\t2022-04-25 15:05\t7.0M\t \n",
    "StormEvents_details-ftp_v1.0_d2005_c20220425.csv.gz\t2022-04-25 15:05\t7.4M\t \n",
    "StormEvents_details-ftp_v1.0_d2006_c20220425.csv.gz\t2022-04-25 15:05\t7.2M\t \n",
    "StormEvents_details-ftp_v1.0_d2007_c20220425.csv.gz\t2022-04-25 15:05\t9.3M\t \n",
    "StormEvents_details-ftp_v1.0_d2008_c20220425.csv.gz\t2022-04-25 15:05\t12M\t \n",
    "StormEvents_details-ftp_v1.0_d2009_c20220425.csv.gz\t2022-04-25 15:05\t9.8M\t \n",
    "StormEvents_details-ftp_v1.0_d2010_c20220425.csv.gz\t2022-04-25 15:05\t11M\t \n",
    "StormEvents_details-ftp_v1.0_d2011_c20220425.csv.gz\t2022-04-25 15:05\t15M\t \n",
    "StormEvents_details-ftp_v1.0_d2012_c20220425.csv.gz\t2022-04-25 15:05\t11M\t \n",
    "StormEvents_details-ftp_v1.0_d2013_c20220425.csv.gz\t2022-04-25 15:05\t11M\t \n",
    "StormEvents_details-ftp_v1.0_d2014_c20220425.csv.gz\t2022-04-25 15:05\t11M\t \n",
    "StormEvents_details-ftp_v1.0_d2015_c20220425.csv.gz\t2022-04-25 15:05\t9.5M\t \n",
    "StormEvents_details-ftp_v1.0_d2016_c20220425.csv.gz\t2022-04-25 15:05\t8.6M\t \n",
    "StormEvents_details-ftp_v1.0_d2017_c20220425.csv.gz\t2022-04-25 15:05\t9.1M\t \n",
    "StormEvents_details-ftp_v1.0_d2018_c20220425.csv.gz\t2022-04-25 15:05\t10M\t \n",
    "StormEvents_details-ftp_v1.0_d2019_c20220425.csv.gz\t2022-04-25 15:05\t11M\t \n",
    "StormEvents_details-ftp_v1.0_d2020_c20220322.csv.gz\t2022-03-22 14:20\t9.9M\t \n",
    "StormEvents_details-ftp_v1.0_d2021_c20220520.csv.gz\t2022-05-20 09:41\t10M\t \n",
    "StormEvents_details-ftp_v1.0_d2022_c20220520.csv.gz\t2022-05-20 09:42\t1.6M\t \n",
    "```\n",
    "\n",
    "The code below reads from this file and creates a list of file names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ece59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('file_names.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "file_names = []\n",
    "for line in lines:\n",
    "    file_names.append(line.split('\\t')[0])\n",
    "file_names = file_names[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41b537",
   "metadata": {},
   "source": [
    "The code below downloads all the CSV files in the list to obtain data for all years (1950 - 2022) from the source URL and then saves to a CSV file `noaa_data.csv`. For some reason, `pd.read_csv()` did not work when running on the Coursera Jupyter Notebook platform, so it had to be run on a local Jupyter Notebook on a laptop computer (which took several minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6b7403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StormEvents_details-ftp_v1.0_d1950_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1951_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1952_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1953_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1954_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1955_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1956_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1957_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1958_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1959_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1960_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1961_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1962_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1963_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1964_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1965_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1966_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1967_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1968_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1969_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1970_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1971_c20210803.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1972_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1973_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1974_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1975_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1976_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1977_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1978_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1979_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1980_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1981_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1982_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1983_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1984_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1985_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1986_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1987_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1988_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1989_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1990_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1991_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1992_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1993_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1994_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1995_c20220425.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t-nishikawa/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (26,48) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StormEvents_details-ftp_v1.0_d1996_c20220425.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t-nishikawa/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (26,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StormEvents_details-ftp_v1.0_d1997_c20220425.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t-nishikawa/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StormEvents_details-ftp_v1.0_d1998_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d1999_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2000_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2001_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2002_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2003_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2004_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2005_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2006_c20220425.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t-nishikawa/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (29,34,35,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StormEvents_details-ftp_v1.0_d2007_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2008_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2009_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2010_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2011_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2012_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2013_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2014_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2015_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2016_c20220425.csv.gz\n",
      "StormEvents_details-ftp_v1.0_d2017_c20220425.csv.gz\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d8db4970f4e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'YEAR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'STATE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TOR_F_SCALE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    559\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34m\"storage_options passed with file object or non-fsspec file path\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             )\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/'\n",
    "df_list = []\n",
    "for fn in file_names:\n",
    "    print(fn)\n",
    "    df = pd.read_csv(url + fn)\n",
    "    df = df[['YEAR', 'STATE', 'TOR_F_SCALE']]\n",
    "    df_list.append(df)\n",
    "pd.concat(df_list).to_csv('noaa_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e66be",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "The code bellow loads the file `noaa_data.csv`, cleans the data frame, and use `groupby()` to count the number of tornado occurrences for the 12 Midwestern state (according to the Census Bureau's definition; source: https://en.wikipedia.org/wiki/Midwestern_United_States). The row for the current year 2022 was dropped since only partial data was available. (Note: `noaa_data.csv` ended up being larger than 30MB and thus could not be uploaded to the Coursera Jupyter Notebook platform.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c122dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('noaa_data.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "g = df.groupby(['YEAR', 'STATE'])\n",
    "df = g.count().unstack().droplevel(0, axis=1)\n",
    "df.index.name = 'Year'\n",
    "df.columns = [s.title() for s in df.columns]\n",
    "df = df.fillna(0)\n",
    "df.drop(2022, axis=0, inplace=True)\n",
    "midwestern_states = [\n",
    "    'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Michigan',\n",
    "    'Minnesota', 'Missouri', 'Nebraska', 'North Dakota',\n",
    "    'Ohio', 'South Dakota', 'Wisconsin'\n",
    "]\n",
    "df = df[midwestern_states]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236fedb9",
   "metadata": {},
   "source": [
    "The code below computes the 10-year rolling average for each state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rolling(10).mean().dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364d201",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "The code below creates the visualization of the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633db9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "yticks = range(20, 121, 20)\n",
    "for y in yticks:\n",
    "    plt.axhline(y, linewidth=0.5, color='k', alpha=0.1)\n",
    "plt.plot(df.index, df, color='b', alpha=0.1)\n",
    "plt.plot(df.index, df['Michigan'], label='Michigan', color='g')\n",
    "plt.plot(df.index, df['Kansas'], label='Kansas', color='r')\n",
    "plt.plot(df.index, df.mean(axis=1), 'b--', label='Midwestern states average', alpha=1)\n",
    "ax = plt.gca()\n",
    "ax.annotate('Kansas', (1999.5, 110), color='r')\n",
    "ax.annotate('Michigan', (2010, 8), color='g')\n",
    "ax.annotate('Average', (2007, 54), color='b')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of tornados', alpha=0.3)\n",
    "for text in ax.get_yticklabels():\n",
    "    text.set_alpha(0.3)\n",
    "plt.title('Number of tornados in 12 Midwestern states')\n",
    "ax.set_yticks(yticks)\n",
    "ax.tick_params(axis='y', length=0)\n",
    "for x in ['top', 'left', 'right']:\n",
    "    ax.spines[x].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98621b45",
   "metadata": {},
   "source": [
    "The green curve shows that the number of tornados in Michigan has stayed low over the past six decades and slightly decreased in the last four decades. This is in contrast with the steady increase in the average number of tornados for the 12 Midwestern states (dashed blue curve) through 2010. The contrast is even larger with the number of tornados in Kansas (red curve), which show much more drastic increase from 1990 to 2010, followed by a sharp drop. The light blue curves in the background correspond to the rest of the Midwestern states.\n",
    "\n",
    "Here is how the visualization incorporates Cairoâ€™s principles:\n",
    "* **Truthfulness.** The choice of using 10-year rolling averages simultaneously allowed for an accurate representation of the trends over several decades and a reduction of noise in the data (i.e., large year-to-year fluctuations).\n",
    "* **Beauty.** The format and color choices for the visual were made to keep it simple and beautiful.\n",
    "* **Functionality.** The design is free of any decorative items and focused on the minimum that is need to tell the story.\n",
    "* **Insightfulness.** The use of color and transparency to highlight the curves for Michigan, Kansas, and the average helps convey the story of how the Michigan number has changed over the last six decades compared to the numbers for the other Midwestern states.\n",
    "\n",
    "Finally, the code below saves the visualization as a PNG image file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('Assignment_4_plot.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
